import cv2
import numpy as np
from ultralytics import YOLO
import supervision as sv
from deep_sort_realtime.deepsort_tracker import DeepSort

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ YOLO11X
model = YOLO("yolo11x.pt")

from coordinates import get_coordinates

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾
video_path = "70kmh_ropazi.mov"
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾.")
    exit()

# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚ Ğ¸Ğ· coordinates.py
try:
    (x1, y1, x2, y2, x3, y3, x4, y4, distance_m,
     blue_x1_top, blue_y1_top, blue_x2_top, blue_y2_top,
     blue_x1_bottom, blue_y1_bottom, blue_x2_bottom, blue_y2_bottom,
     blue_line_thickness) = get_coordinates(video_path)
except ValueError as e:
    print(e)
    cap.release()
    exit()

# Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ ĞºĞ°Ğ´Ñ€
ret, frame = cap.read()
if not ret:
    print("ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ ĞºĞ°Ğ´Ñ€.")
    cap.release()
    exit()

# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = int(cap.get(cv2.CAP_PROP_FPS))

# Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¾ĞºĞ½Ğ° Ğ´Ğ»Ñ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ (Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ ĞºĞ°Ğ´Ñ€ Ğ²Ğ»ĞµĞ·Ğ°Ğ» Ğ² ÑĞºÑ€Ğ°Ğ½)
screen_width, screen_height = 1280, 720
scale = min(screen_width / frame_width, screen_height / frame_height)
new_width = int(frame_width * scale)
new_height = int(frame_height * scale)

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
output_path = "output.mp4"
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

# # ğŸŸ¥ ĞšĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ñ‹ Ñ€Ğ°Ğ¼ĞºĞ¸ Ğ¸ ÑĞ¸Ğ½Ğ¸Ñ… Ğ»Ğ¸Ğ½Ğ¸Ğ¹ Ğ¿Ğ¾Ğ´ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾
# if "50kmh_mugur_jaunolaine" in video_path.lower():
#     # ĞšÑ€Ğ°ÑĞ½Ğ°Ñ Ñ€Ğ°Ğ¼ĞºĞ°
#     x1, y1 = 5000, 2900      # AugÅ¡Ä“jais labais stÅ«ris
#     x2, y2 = 4000, 2900     # AugÅ¡Ä“jais kreisais stÅ«ris
#     x3, y3 = 7400, 6000     # Kreisais apakÅ¡Ä“jais stÅ«ris
#     x4, y4 = 10500, 4600    # ApakÅ¡Ä“jais labais stÅ«ris
#     distance_m = 200

#     # ğŸŸ¦ Ğ¡Ğ¸Ğ½Ğ¸Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸
#     blue_x1_top, blue_y1_top = 5000, 3050           # AugÅ¡Ä“jais kreisais stÅ«ris
#     blue_x2_top, blue_y2_top = 5300, 3050           # AugÅ¡Ä“jais labais stÅ«ris
#     blue_x1_bottom, blue_y1_bottom = 7400, 5000     # Kreisais apakÅ¡Ä“jais stÅ«ris
#     blue_x2_bottom, blue_y2_bottom = 10900, 5250    # ApakÅ¡Ä“jais labais stÅ«ris

#     blue_line_thickness = 3

# elif "50kmh_prieksa_jaunolaine" in video_path.lower():
#     # ĞšÑ€Ğ°ÑĞ½Ğ°Ñ Ñ€Ğ°Ğ¼ĞºĞ°
#     x1, y1 = 5200, 3000     # AugÅ¡Ä“jais labais stÅ«ris
#     x2, y2 = 4900, 3000     # AugÅ¡Ä“jais kreisais stÅ«ris
#     x3, y3 = 7950, 5500     # Kreisais apakÅ¡Ä“jais stÅ«ris
#     x4, y4 = 11000, 4800    # ApakÅ¡Ä“jais labais stÅ«ris
#     distance_m = 60

#     # ğŸŸ¦ Ğ¡Ğ¸Ğ½Ğ¸Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸
#     blue_x1_top, blue_y1_top = 4950, 3100           # AugÅ¡Ä“jais kreisais stÅ«ris
#     blue_x2_top, blue_y2_top = 5550, 3075           # AugÅ¡Ä“jais labais stÅ«ris
#     blue_x1_bottom, blue_y1_bottom = 7400, 5500     # Kreisais apakÅ¡Ä“jais stÅ«ris
#     blue_x2_bottom, blue_y2_bottom = 11000, 4750    # ApakÅ¡Ä“jais labais stÅ«ris

#     blue_line_thickness = 3

# elif "70kmh_mugur_jaunolaine" in video_path.lower():
#     # ĞšÑ€Ğ°ÑĞ½Ğ°Ñ Ñ€Ğ°Ğ¼ĞºĞ°
#     x1, y1 = 4950, 2850     # AugÅ¡Ä“jais labais stÅ«ris
#     x2, y2 = 3950, 2850     # AugÅ¡Ä“jais kreisais stÅ«ris
#     x3, y3 = 7300, 5900     # Kreisais apakÅ¡Ä“jais stÅ«ris
#     x4, y4 = 10400, 4550     # ApakÅ¡Ä“jais labais stÅ«ris
#     distance_m = 200

#     # ğŸŸ¦ Ğ¡Ğ¸Ğ½Ğ¸Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸
#     blue_x1_top, blue_y1_top = 5000, 3050           # AugÅ¡Ä“jais kreisais stÅ«ris
#     blue_x2_top, blue_y2_top = 5300, 3050           # AugÅ¡Ä“jais labais stÅ«ris
#     blue_x1_bottom, blue_y1_bottom = 7400, 5000     # Kreisais apakÅ¡Ä“jais stÅ«ris
#     blue_x2_bottom, blue_y2_bottom = 10900, 5250    # ApakÅ¡Ä“jais labais stÅ«ris

#     blue_line_thickness = 3

# elif "70kmh_prieksa_jaunolaine" in video_path.lower():
#     # ĞšÑ€Ğ°ÑĞ½Ğ°Ñ Ñ€Ğ°Ğ¼ĞºĞ°
#     x1, y1 = 5150, 3000   # AugÅ¡Ä“jais labais stÅ«ris
#     x2, y2 = 4750, 3000   # AugÅ¡Ä“jais kreisais stÅ«ris
#     x3, y3 = 8000, 6000   # Kreisais apakÅ¡Ä“jais stÅ«ris
#     x4, y4 = 10700, 4600  # ApakÅ¡Ä“jais labais stÅ«ris
#     distance_m = 60

#     # ğŸŸ¦ Ğ¡Ğ¸Ğ½Ğ¸Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸
#     blue_x1_top, blue_y1_top = 5200, 3025         # AugÅ¡Ä“jais kreisais stÅ«ris
#     blue_x2_top, blue_y2_top = 4800, 3050         # AugÅ¡Ä“jais labais stÅ«ris
#     blue_x1_bottom, blue_y1_bottom = 7950, 5950   # Kreisais apakÅ¡Ä“jais stÅ«ris
#     blue_x2_bottom, blue_y2_bottom = 10650, 4550  # ApakÅ¡Ä“jais labais stÅ«ris

#     blue_line_thickness = 3

# elif "50kmh_ropazi" in video_path.lower():
#     # ĞšÑ€Ğ°ÑĞ½Ğ°Ñ Ñ€Ğ°Ğ¼ĞºĞ°
#     x1, y1 = 6400, 2900     # AugÅ¡Ä“jais labais stÅ«ris
#     x2, y2 = 5700, 2900     # AugÅ¡Ä“jais kreisais stÅ«ris
#     x3, y3 = 500, 5800      # Kreisais apakÅ¡Ä“jais stÅ«ris
#     x4, y4 = 6900, 5800     # ApakÅ¡Ä“jais labais stÅ«ris
#     distance_m = 150

#     # ğŸŸ¦ Ğ¡Ğ¸Ğ½Ğ¸Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸ (Ğ½Ğ°ĞºĞ»Ğ¾Ğ½Ğ½Ñ‹Ğµ)
#     blue_x1_top, blue_y1_top = 5000, 3050           # AugÅ¡Ä“jais kreisais stÅ«ris
#     blue_x2_top, blue_y2_top = 5300, 3050           # AugÅ¡Ä“jais labais stÅ«ris
#     blue_x1_bottom, blue_y1_bottom = 7400, 5000     # Kreisais apakÅ¡Ä“jais stÅ«ris
#     blue_x2_bottom, blue_y2_bottom = 10900, 5250    # ApakÅ¡Ä“jais labais stÅ«ris

#     blue_line_thickness = 3

# elif "70kmh_ropazi" in video_path.lower():
#     # ĞšÑ€Ğ°ÑĞ½Ğ°Ñ Ñ€Ğ°Ğ¼ĞºĞ°
#     x1, y1 = 6400, 3200     # AugÅ¡Ä“jais labais stÅ«ris
#     x2, y2 = 5700, 3200     # AugÅ¡Ä“jais Kreisais stÅ«ris
#     x3, y3 = 500, 5700     # ApakÅ¡Ä“jais Kreisais stÅ«ris
#     x4, y4 = 6600, 6200    # labais apakÅ¡Ä“jais stÅ«ris
#     distance_m =45

#     # ğŸŸ¦ Ğ¡Ğ¸Ğ½Ğ¸Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸
#     blue_x1_top, blue_y1_top = 5350, 3275           # AugÅ¡Ä“jais kreisais stÅ«ris
#     blue_x2_top, blue_y2_top = 6400, 3275           # AugÅ¡Ä“jais labais stÅ«ris
#     blue_x1_bottom, blue_y1_bottom = 1050, 5500     # Kreisais apakÅ¡Ä“jais stÅ«ris
#     blue_x2_bottom, blue_y2_bottom = 6450, 5900    # ApakÅ¡Ä“jais labais stÅ«ris

#     blue_line_thickness = 3

# elif "80kmh_ropazi" in video_path.lower():
#     # ĞšÑ€Ğ°ÑĞ½Ğ°Ñ Ñ€Ğ°Ğ¼ĞºĞ°
#     x1, y1 = 6600, 3000     # AugÅ¡Ä“jais labais stÅ«ris
#     x2, y2 = 5900, 3000     # AugÅ¡Ä“jais kreisais stÅ«ris
#     x3, y3 = 600, 5900      # Kreisais apakÅ¡Ä“jais stÅ«ris
#     x4, y4 = 7000, 5900     # ApakÅ¡Ä“jais labais stÅ«ris
#     distance_m = 150

#     # ğŸŸ¦ Ğ¡Ğ¸Ğ½Ğ¸Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸
#     blue_x1_top, blue_y1_top = 5000, 3050           # AugÅ¡Ä“jais kreisais stÅ«ris
#     blue_x2_top, blue_y2_top = 5300, 3050           # AugÅ¡Ä“jais labais stÅ«ris
#     blue_x1_bottom, blue_y1_bottom = 7400, 5000     # Kreisais apakÅ¡Ä“jais stÅ«ris
#     blue_x2_bottom, blue_y2_bottom = 10900, 5250    # ApakÅ¡Ä“jais labais stÅ«ris

#     blue_line_thickness = 3

# else:
#     print("ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¹ Ñ‚Ğ¸Ğ¿ Ğ²Ğ¸Ğ´ĞµĞ¾.")
#     cap.release()
#     exit()



# ĞŸÑ€Ğ¸Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚ Ğº Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ñƒ
x1, x2, x3, x4 = int(x1 * scale), int(x2 * scale), int(x3 * scale), int(x4 * scale)
y1, y2, y3, y4 = int(y1 * scale), int(y2 * scale), int(y3 * scale), int(y4 * scale)

blue_x1_top, blue_x2_top = int(blue_x1_top * scale), int(blue_x2_top * scale)
blue_y1_top, blue_y2_top = int(blue_y1_top * scale), int(blue_y2_top * scale)
blue_x1_bottom, blue_x2_bottom = int(blue_x1_bottom * scale), int(blue_x2_bottom * scale)
blue_y1_bottom, blue_y2_bottom = int(blue_y1_bottom * scale), int(blue_y2_bottom * scale)

src = np.array([
    [blue_x1_top, blue_y1_top],
    [blue_x2_top, blue_y2_top],
    [blue_x1_bottom, blue_y1_bottom],
    [blue_x2_bottom, blue_y2_bottom]
    #[blue_x1_bottom, blue_y1_bottom]
], dtype=np.float32)

dst = np.array([
    [0, 0],
    [6, 0],  # ÑˆĞ¸Ñ€Ğ¸Ğ½Ğ° Ğ¿Ğ¾Ğ»Ğ¾ÑÑ‹ â€” 4 Ğ¼
    [0, distance_m],     # 60 Ğ¼ Ğ¿Ğ¾ Ğ²ĞµÑ€Ñ‚Ğ¸ĞºĞ°Ğ»Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞ¸Ğ½Ğ¸Ğ¼Ğ¸ Ğ»Ğ¸Ğ½Ğ¸ÑĞ¼Ğ¸
    [6, distance_m]
], dtype=np.float32)

matrix = cv2.getPerspectiveTransform(src, dst)


# ĞšÑ€Ğ°ÑĞ½Ğ°Ñ Ñ€Ğ°Ğ¼ĞºĞ° (Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑŒ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ°)
pts = np.array([[x1, y1], [x2, y2], [x3, y3], [x4, y4]], np.int32)

# ğŸ”´ ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ ĞºĞ°Ğ´Ñ€ Ñ Ñ€Ğ°Ğ¼ĞºĞ¾Ğ¹ Ğ¸ ÑĞ¸Ğ½Ğ¸Ğ¼Ğ¸ Ğ»Ğ¸Ğ½Ğ¸ÑĞ¼Ğ¸
frame_with_zone = frame.copy()
# Ğ Ğ¸ÑÑƒĞµĞ¼ ĞºÑ€Ğ°ÑĞ½ÑƒÑ Ñ€Ğ°Ğ¼ĞºÑƒ
cv2.polylines(frame_with_zone, [pts], isClosed=True, color=(0, 0, 255), thickness=3)
# Ğ Ğ¸ÑÑƒĞµĞ¼ ÑĞ¸Ğ½Ğ¸Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸
# ğŸŸ¦ Ğ Ğ¸ÑÑƒĞµĞ¼ ÑĞ¸Ğ½Ğ¸Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸ (Ğ½Ğ°ĞºĞ»Ğ¾Ğ½Ğ½Ñ‹Ğµ)
# ğŸ”µ Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ¸Ğ½Ğ¸Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸ Ğ² `frame_with_zone`
cv2.line(frame_with_zone, (blue_x1_top, blue_y1_top), (blue_x2_top, blue_y2_top), (255, 0, 0), blue_line_thickness)
cv2.line(frame_with_zone, (blue_x1_bottom, blue_y1_bottom), (blue_x2_bottom, blue_y2_bottom), (255, 0, 0), blue_line_thickness)

# ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ»Ñ ÑĞºÑ€Ğ°Ğ½Ğ° Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼
resized_frame = cv2.resize(frame_with_zone, (new_width, new_height))
cv2.imshow("ĞĞ±Ğ»Ğ°ÑÑ‚ÑŒ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ° (Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ ĞºĞ°Ğ´Ñ€)", resized_frame)
cv2.waitKey(0)
cv2.destroyAllWindows()

# ğŸ“Œ Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸, Ğ²Ñ‹ÑˆĞµ Ğ»Ğ¸ Ñ‚Ğ¾Ñ‡ĞºĞ° (cx, cy) Ğ½Ğ°ĞºĞ»Ğ¾Ğ½Ğ½Ğ¾Ğ¹ Ğ»Ğ¸Ğ½Ğ¸Ğ¸
def is_above_line(cx, cy, x1, y1, x2, y2):
    if x1 == x2:
        return cx <= x1
    m = (y2 - y1) / (x2 - x1)
    b = y1 - m * x1
    y_on_line = m * cx + b
    return cy <= y_on_line

# ğŸŸ¢ ĞĞ½Ğ½Ğ¾Ñ‚Ğ°Ñ‚Ğ¾Ñ€Ñ‹
box_annotator = sv.BoxAnnotator(color=sv.Color.GREEN, thickness=2)

label_annotator = sv.LabelAnnotator(
    text_color=sv.Color.BLACK,       # Ñ†Ğ²ĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ°
)

from collections import defaultdict, deque

# Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Y-ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚ Ğ² Ğ¼ĞµÑ‚Ñ€Ğ°Ñ… Ğ¿Ğ¾ÑĞ»Ğµ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ â€” Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ 1 ÑĞµĞºÑƒĞ½Ğ´Ñƒ
real_y_history = defaultdict(lambda: deque(maxlen=int(fps)))


# Deep SORT Ñ‚Ñ€ĞµĞºĞµÑ€
tracker = DeepSort(max_age=30)

# Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ğ´Ğ»Ñ Ğ·Ğ°ÑĞµÑ‡ĞºĞ¸ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸
vehicle_timestamps = {}

# Ğ¥Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ²ÑĞµÑ… ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ĞµĞ¹ Ğ¿Ğ¾ ÑĞ´Ğ²Ğ¸Ğ³Ñƒ
vehicle_speeds_shift = defaultdict(list)  


# ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ĞºĞ°Ğ´Ñ€Ğ¾Ğ²
frame_count = 0
cap.set(cv2.CAP_PROP_POS_FRAMES, 0)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame_time = frame_count / fps
    frame_count += 1

    results = model(frame)
    detections = []
    boxes_for_tracking = []

    for result in results:
        for box in result.boxes:
            x_min, y_min, x_max, y_max = map(int, box.xyxy[0])
            conf = box.conf[0].item()
            cls = int(box.cls[0].item())

            if cls != 2:
                continue

            if not cv2.pointPolygonTest(pts, ((x_min + x_max) // 2, (y_min + y_max) // 2), False) >= 0:
                continue

            boxes_for_tracking.append(([x_min, y_min, x_max - x_min, y_max - y_min], conf, 'car'))

    tracks = tracker.update_tracks(boxes_for_tracking, frame=frame)
    
    tracked_boxes = []
    confidences = []
    class_ids = []
    labels = []

    for track in tracks:
    
        if not track.is_confirmed():
            continue

        track_id = track.track_id

        # ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ñ‹ Ñ†ĞµĞ½Ñ‚Ñ€Ğ°
        l, t, r, b = map(int, track.to_ltrb())
        cx = (l + r) // 2
        cy = b  # Ğ½Ğ¸Ğ¶Ğ½ÑÑ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ° (bottom)


        # Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ğ°
        real_point = cv2.perspectiveTransform(
            np.array([[[cx, cy]]], dtype=np.float32),
           matrix
        )[0][0]


        real_y_history[track_id].append(real_point)  # ÑÑ‚Ğ¾ ÑƒĞ¶Ğµ (x, y)


        # ĞµÑĞ»Ğ¸ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ° ÑƒĞ¶Ğµ Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ° Ğ¾Ğ±Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸ â€” Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ´ĞµĞ»Ğ°ĞµĞ¼
        if vehicle_timestamps.get(track_id, {}).get("done"):
            continue


        speed_transformed = None

        # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ»Ğ¸Ğ½Ğ¸ÑĞ¼Ğ¸
        if is_above_line(cx, cy, blue_x1_bottom, blue_y1_bottom, blue_x2_bottom, blue_y2_bottom) and \
           not is_above_line(cx, cy, blue_x1_top, blue_y1_top, blue_x2_top, blue_y2_top):
            
            if len(real_y_history[track_id]) >= 2:
                # ĞŸĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ²ÑÑ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Y-ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚ Ğ² Ğ¼Ğ°ÑÑĞ¸Ğ² Ñ‚Ğ¾Ñ‡ĞµĞº (x, y)
                points = np.array(real_y_history[track_id], dtype=np.float32)

                # Ğ¡Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ñƒ Ğ¿ÑƒÑ‚Ğ¸ Ğ²Ğ´Ğ¾Ğ»ÑŒ Ğ²ÑĞµĞ¹ Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸
                distances = np.linalg.norm(np.diff(points, axis=0), axis=1)
                total_distance = np.sum(distances)
                time_delta = len(real_y_history[track_id]) / fps

                if time_delta > 0 and total_distance > 0.1:
                    speed_transformed = (total_distance / time_delta) * 3.6



        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾ ÑĞ´Ğ²Ğ¸Ğ³Ñƒ
        if speed_transformed is not None:
            # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ ÑĞºĞ°Ñ‡ĞºĞ¾Ğ² ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ (Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ +30% Ğ¾Ñ‚ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ¹)
            if len(vehicle_speeds_shift[track_id]) > 0:
                last_speed = vehicle_speeds_shift[track_id][-1]
                if abs(speed_transformed - last_speed) > last_speed * 0.3:  # ĞĞµ Ğ±Ğ¾Ğ»ĞµĞµ 30% ÑĞºĞ°Ñ‡ĞºĞ°
                    speed_transformed = last_speed

            vehicle_speeds_shift[track_id].append(speed_transformed)


        # ĞœĞµÑ‚Ğ¾Ğ´ Ñ Ğ»Ğ¸Ğ½Ğ¸ÑĞ¼Ğ¸ (Ğ¾ÑÑ‚Ğ°Ğ»ÑÑ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
        if track_id not in vehicle_timestamps:
            vehicle_timestamps[track_id] = {
            "start": None,
            "end": None,
            "last_position": cy,
            "done": False
        }


        last_cy = vehicle_timestamps[track_id]["last_position"]

        # â• ĞŸĞµÑ€ĞµĞ´ Ñ€Ğ°ÑÑ‡Ñ‘Ñ‚Ğ¾Ğ¼ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸, Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ:
        direction = cy - last_cy  # + Ğ²Ğ½Ğ¸Ğ·, - Ğ²Ğ²ĞµÑ€Ñ…

        # â›” Ğ•ÑĞ»Ğ¸ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ° Ğ´Ğ²Ğ¸Ğ¶ĞµÑ‚ÑÑ Ğ²Ğ²ĞµÑ€Ñ… (Ğ¾Ñ‚ Ğ½Ğ¸Ğ¶Ğ½ĞµĞ¹ Ğº Ğ²ĞµÑ€Ñ…Ğ½ĞµĞ¹ Ğ»Ğ¸Ğ½Ğ¸Ğ¸), Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ Ñ€Ğ°ÑÑ‡Ñ‘Ñ‚Ñ‹
        if direction < -2:  # Ñ Ğ¿Ğ¾Ñ€Ğ¾Ğ³Ğ¾Ğ¼ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
            continue



        if vehicle_timestamps[track_id]["start"] is None and is_above_line(cx, cy, blue_x1_top, blue_y1_top, blue_x2_top, blue_y2_top):
            vehicle_timestamps[track_id]["start"] = frame_time

        if vehicle_timestamps[track_id]["end"] is None and not is_above_line(cx, cy, blue_x1_bottom, blue_y1_bottom, blue_x2_bottom, blue_y2_bottom):
            vehicle_timestamps[track_id]["end"] = frame_time
            vehicle_timestamps[track_id]["done"] = True  # Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ


        vehicle_timestamps[track_id]["last_position"] = cy


       # ğŸŸ© Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ»Ñ Ğ¾Ñ‚Ñ€Ğ¸ÑĞ¾Ğ²ĞºĞ¸
        tracked_boxes.append([l, t, r, b])
        confidences.append(1.0)
        class_ids.append(2)

        # ğŸ· Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ Ñ Ğ¾Ğ±ĞµĞ¸Ğ¼Ğ¸ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑĞ¼Ğ¸
        label_parts = []

        if speed_transformed is not None:
            label_parts.append(f"T: {speed_transformed:.1f} km/h")

        if vehicle_timestamps[track_id]["start"] is not None and vehicle_timestamps[track_id]["end"] is not None:
            travel_time = vehicle_timestamps[track_id]["end"] - vehicle_timestamps[track_id]["start"]
            if travel_time > 0:
                speed_line = (distance_m / travel_time) * 3.6
                label_parts.append(f"L: {speed_line:.1f} km/h")

        if not label_parts:
            label_parts.append("Tracking...")

        labels.append(" | ".join(label_parts))



    if tracked_boxes:
        detections_sv = sv.Detections(
            xyxy=np.array(tracked_boxes),
            confidence=np.array(confidences),
            class_id=np.array(class_ids)
        )

        # ğŸŸ© ĞÑ‚Ñ€Ğ¸ÑĞ¾Ğ²ĞºĞ° Ğ±Ğ¾ĞºÑĞ¾Ğ² Ğ¸ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞµĞ¹
        frame = box_annotator.annotate(scene=frame, detections=detections_sv)
        frame = label_annotator.annotate(scene=frame, detections=detections_sv, labels=labels)


    cv2.line(frame, (blue_x1_top, blue_y1_top), (blue_x2_top, blue_y2_top), (255, 0, 0), blue_line_thickness)
    cv2.line(frame, (blue_x1_bottom, blue_y1_bottom), (blue_x2_bottom, blue_y2_bottom), (255, 0, 0), blue_line_thickness)
    # ğŸŸ¥ ĞšÑ€Ğ°ÑĞ½Ğ°Ñ Ñ€Ğ°Ğ¼ĞºĞ°
    cv2.polylines(frame, [pts], isClosed=True, color=(0, 0, 255), thickness=2)

    out.write(frame)

# Ğ’Ñ‹Ğ²Ğ¾Ğ´ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¾Ğ±Ğ¾Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²
print("\nğŸ“Š Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğµ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸:")

for vehicle_id, times in vehicle_timestamps.items():
    if times["start"] is not None and times["end"] is not None:
        travel_time = times["end"] - times["start"]
        speed_kmh = (distance_m / travel_time) * 3.6
        print(f"ğŸš— ĞœĞ°ÑˆĞ¸Ğ½Ğ° {vehicle_id}: L: {speed_kmh:.2f} ĞºĞ¼/Ñ‡")

for vehicle_id, speeds in vehicle_speeds_shift.items():
    if speeds:
        avg_speed_shift = sum(speeds) / len(speeds)
        print(f"ğŸš— ĞœĞ°ÑˆĞ¸Ğ½Ğ° {vehicle_id}: T: {avg_speed_shift:.2f} ĞºĞ¼/Ñ‡")

cap.release()
out.release()
cv2.destroyAllWindows()


cap.release()
out.release()
cv2.destroyAllWindows()

print(f"âœ… ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ ĞºĞ°Ğº {output_path}")
